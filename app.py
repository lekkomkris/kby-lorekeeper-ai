# /thanpanya-ai/app.py

import streamlit as st
import openai
from typing import List, Dict

# Local Imports
from config import PAGE_CONFIG, SUPPORTED_MODELS, DEFAULT_MODEL, DEFAULT_TEMP, LORE_FILEPATH, EMBEDDING_MODEL, TOP_K_RESULTS
from retrievers import get_vector_retriever
from core import TharnpanyaKernel

# --- Main Application Logic ---
def main():
    st.set_page_config(**PAGE_CONFIG)

    # --- Initialization ---
    try:
        openai.api_key = st.secrets["OPENAI_API_KEY"]
        retriever = get_vector_retriever(LORE_FILEPATH, EMBEDDING_MODEL)
        kernel = TharnpanyaKernel(retriever)
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö: {e}", icon="üö®")
        return

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # --- Sidebar UI ---
    with st.sidebar:
        st.header("‚öôÔ∏è ‡πÅ‡∏ú‡∏á‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ò‡∏≤‡∏£‡∏õ‡∏±‡∏ç‡∏ç‡∏≤ v2.0")
        model = st.selectbox("üîÅ GPT Model", SUPPORTED_MODELS, index=SUPPORTED_MODELS.index(DEFAULT_MODEL))
        temp = st.slider("üéõÔ∏è ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå", 0.0, 1.5, DEFAULT_TEMP, 0.05)
        
        st.markdown("---")
        if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"):
            st.session_state.messages = []
            st.rerun()

    # --- Main Chat UI ---
    st.title(PAGE_CONFIG["page_title"])
    st.caption("‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏∑‡∏≠‡∏à‡∏¥‡∏ï‡∏™‡∏≥‡∏ô‡∏∂‡∏Å AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô, ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢")

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if user_question := st.chat_input("‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≤‡∏™‡∏¥..."):
        st.session_state.messages.append({"role": "user", "content": user_question})
        with st.chat_message("user"):
            st.markdown(user_question)

        with st.chat_message("assistant", avatar="‚ú®"):
            message_placeholder = st.empty()
            with st.spinner("‚ö°Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏™‡∏≤‡∏¢‡∏ò‡∏≤‡∏£‡πÅ‡∏´‡πà‡∏á‡∏õ‡∏±‡∏ç‡∏ç‡∏≤..."):
                
                # Get the last few messages for context, to avoid overly long prompts
                chat_history = st.session_state.messages[-10:-1] 

                result = kernel.query(user_question, chat_history, model, temp, TOP_K_RESULTS)

                if "error" in result:
                    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {result['error']}")
                else:
                    full_response = ""
                    # Stream the response
                    for chunk in result["response_stream"]:
                        full_response += (chunk.choices[0].delta.content or "")
                        message_placeholder.markdown(full_response + "‚ñå")
                    message_placeholder.markdown(full_response)
                    
                    # Calculate completion tokens and cost after streaming
                    completion_tokens = len(kernel.encoder.encode(full_response))
                    cost = kernel.calculate_cost(model, result["prompt_tokens"], completion_tokens)
                    
                    # Display context and cost
                    with st.expander("üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"):
                        st.json({"contexts_used": result["contexts"]})
                        st.info(f"""
                        **‡∏ú‡∏•‡∏∂‡∏Å‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ:**
                        - **Model:** `{model}`
                        - **Prompt Tokens:** `{result["prompt_tokens"]}`
                        - **Completion Tokens:** `{completion_tokens}`
                        - **Estimated Cost:** `${cost:.6f}`
                        """)

                    st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()